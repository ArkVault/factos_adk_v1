#!/usr/bin/env python3
"""
Test r√°pido para verificar la calidad del an√°lisis contextualizado.
"""

import asyncio
import os
import sys
sys.path.append('/Users/gibrann/Documents/factos_agents')

from adk_project.agents.response_formatter_agent.response_formatter_agent import ResponseFormatterAgent

async def test_analysis_methods():
    """Test directo de los m√©todos de an√°lisis mejorados"""
    
    print("üß™ TESTING M√âTODOS DE AN√ÅLISIS CONTEXTUALIZADO")
    print("=" * 60)
    
    formatter = ResponseFormatterAgent()
    
    # Test 1: An√°lisis de verosimilitud
    print("\nüìä TEST 1: AN√ÅLISIS DE VEROSIMILITUD")
    print("-" * 40)
    
    test_claim = "Un nuevo estudio muestra que el ejercicio reduce el riesgo de c√°ncer en un 50%"
    fake_matches = {
        'matches': [
            {
                'source': 'FactCheck.org',
                'relation_type': 'relacionado',
                'confidence': 'medio',
                'main_claim': 'Estudios muestran beneficios del ejercicio contra el c√°ncer'
            }
        ],
        'semantic_analysis': {
            'explanation': 'Se encontraron estudios relacionados pero con cifras diferentes'
        }
    }
    
    analysis = formatter._generate_recommendation(
        score=3,
        main_claim=test_claim,
        detailed_analysis="An√°lisis t√©cnico de ejemplo",
        fact_check_results=fake_matches
    )
    
    print(f"üìù Claim: {test_claim}")
    print(f"üîç An√°lisis generado ({len(analysis)} caracteres):")
    print(f"üìÑ {analysis}")
    
    # Test 2: Consejo de alfabetizaci√≥n medi√°tica
    print("\nüéì TEST 2: CONSEJO DE ALFABETIZACI√ìN MEDI√ÅTICA")
    print("-" * 40)
    
    media_tip = formatter._generate_media_literacy_tip(
        score=3,
        main_claim=test_claim,
        article_domain="healthnews.com"
    )
    
    print(f"üìù Claim: {test_claim}")
    print(f"üåê Dominio: healthnews.com") 
    print(f"üí° Consejo generado ({len(media_tip)} caracteres):")
    print(f"üìÑ {media_tip}")
    
    # Test 3: An√°lisis sin matches (caso m√°s com√∫n)
    print("\nüîç TEST 3: AN√ÅLISIS SIN MATCHES DE FACT-CHECKERS")
    print("-" * 40)
    
    no_matches = {'matches': [], 'semantic_analysis': {'explanation': 'No se encontraron verificaciones relacionadas'}}
    
    analysis_no_match = formatter._generate_recommendation(
        score=2,
        main_claim="Los diplom√°ticos fueron evacuados tras escuchar disparos",
        detailed_analysis="Evento reportado por m√∫ltiples fuentes",
        fact_check_results=no_matches
    )
    
    print(f"üìù Claim: Diplom√°ticos evacuados tras disparos")
    print(f"üîç An√°lisis sin matches ({len(analysis_no_match)} caracteres):")
    print(f"üìÑ {analysis_no_match}")
    
    print("\n" + "=" * 60)
    print("‚úÖ TESTS DE AN√ÅLISIS COMPLETADOS")
    
    # Evaluaci√≥n de calidad
    print("\nüìà EVALUACI√ìN DE CALIDAD:")
    
    quality_metrics = {
        "Longitud adecuada (>100 chars)": len(analysis) > 100 and len(media_tip) > 80,
        "Menciona fact-checking": "fact-check" in analysis.lower() or "verificaci√≥n" in analysis.lower(),
        "Espec√≠fico al claim": "estudio" in analysis.lower() or "ejercicio" in analysis.lower(),
        "Consejo pr√°ctico": any(word in media_tip.lower() for word in ['verifica', 'eval√∫a', 'confirma']),
        "Tono profesional": "An√°lisis" in analysis and not "gen√©ric" in analysis.lower()
    }
    
    for metric, passed in quality_metrics.items():
        status = "‚úÖ" if passed else "‚ùå"
        print(f"{status} {metric}")
    
    score = sum(quality_metrics.values()) / len(quality_metrics)
    print(f"\nüéØ PUNTUACI√ìN GENERAL: {score:.1%}")
    
    if score >= 0.8:
        print("üéâ ¬°Excelente calidad!")
    elif score >= 0.6:
        print("‚úÖ Buena calidad")
    else:
        print("‚ö†Ô∏è Necesita mejoras")

if __name__ == "__main__":
    asyncio.run(test_analysis_methods())
